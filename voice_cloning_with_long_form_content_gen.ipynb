{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"execution":{"iopub.execute_input":"2023-10-30T08:36:35.967923Z","iopub.status.busy":"2023-10-30T08:36:35.967015Z","iopub.status.idle":"2023-10-30T08:36:51.680469Z","shell.execute_reply":"2023-10-30T08:36:51.679440Z","shell.execute_reply.started":"2023-10-30T08:36:35.967889Z"},"id":"kKoBLcvQlmm-","jupyter":{"outputs_hidden":true},"outputId":"c191497e-0a4a-4628-9a42-099a1e223b97","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: bark in /opt/conda/lib/python3.10/site-packages (0.1.5)\n","Collecting ffprobe\n","  Downloading ffprobe-0.5.zip (3.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n","Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from bark) (1.26.100)\n","Requirement already satisfied: encodec in /opt/conda/lib/python3.10/site-packages (from bark) (0.1.1)\n","Requirement already satisfied: funcy in /opt/conda/lib/python3.10/site-packages (from bark) (2.0)\n","Requirement already satisfied: huggingface-hub>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from bark) (0.16.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bark) (1.23.5)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bark) (1.11.2)\n","Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from bark) (0.13.3)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bark) (2.0.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from bark) (4.66.1)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from bark) (4.33.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (3.12.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (2023.9.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.1->bark) (21.3)\n","Requirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.10/site-packages (from boto3->bark) (1.29.165)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->bark) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->bark) (0.6.2)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from encodec->bark) (2.0.1)\n","Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from encodec->bark) (0.7.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bark) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bark) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bark) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->bark) (2023.6.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->bark) (0.3.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->bark) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->bark) (1.26.15)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.14.1->bark) (3.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bark) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.14.1->bark) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.14.1->bark) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.14.1->bark) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bark) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->bark) (1.16.0)\n","Building wheels for collected packages: ffprobe, ffmpeg\n","  Building wheel for ffprobe (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffprobe: filename=ffprobe-0.5-py3-none-any.whl size=3405 sha256=66e281df04e7efce11de3322198c5fd23968fb8fffddfb039e3ecf459ca3cd5b\n","  Stored in directory: /root/.cache/pip/wheels/a2/66/e3/5da9a7e12ee519eed653b188eb8dd7ca780f5c882922beb15d\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=751d3a89aa57c3698a7b7896d11861a702d52df49365b2bb4d790b7d9b660c5e\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built ffprobe ffmpeg\n","Installing collected packages: ffprobe, ffmpeg\n","Successfully installed ffmpeg-1.4 ffprobe-0.5\n"]}],"source":["!pip install bark ffprobe ffmpeg pydub"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:37:48.608800Z","iopub.status.busy":"2023-10-30T08:37:48.608419Z","iopub.status.idle":"2023-10-30T08:37:48.828803Z","shell.execute_reply":"2023-10-30T08:37:48.827986Z","shell.execute_reply.started":"2023-10-30T08:37:48.608771Z"},"trusted":true},"outputs":[],"source":["from pydub import AudioSegment\n","\n","m4a_file = '/kaggle/input/prompt2/Prompt1.m4a' # I have downloaded sample audio from this link https://getsamplefiles.com/sample-audio-files/m4a\n","wav_filename = '/kaggle/working/output.wav'\n","\n","sound = AudioSegment.from_file(m4a_file, format='m4a')\n","file_handle = sound.export(wav_filename, format='wav')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-30T08:39:05.503312Z","iopub.status.busy":"2023-10-30T08:39:05.502669Z","iopub.status.idle":"2023-10-30T08:39:05.514007Z","shell.execute_reply":"2023-10-30T08:39:05.513178Z","shell.execute_reply.started":"2023-10-30T08:39:05.503280Z"},"id":"wSZyoiatieBM","outputId":"4f55ebdc-5b06-426b-bc25-97098bb4eac6","trusted":true},"outputs":[],"source":["from bark.generation import load_codec_model, generate_text_semantic\n","from encodec.utils import convert_audio\n","\n","import torchaudio\n","import torch\n","import numpy as np\n","\n","device = 'cuda' # or 'cpu'\n","model = load_codec_model(use_gpu=True if device == 'cuda' else False)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:27:58.997422Z","iopub.status.busy":"2023-10-30T08:27:58.996400Z","iopub.status.idle":"2023-10-30T08:27:59.004236Z","shell.execute_reply":"2023-10-30T08:27:59.003249Z","shell.execute_reply.started":"2023-10-30T08:27:58.997390Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-10-30T08:28:06.421503Z","iopub.status.busy":"2023-10-30T08:28:06.421106Z","iopub.status.idle":"2023-10-30T08:28:31.576074Z","shell.execute_reply":"2023-10-30T08:28:31.574915Z","shell.execute_reply.started":"2023-10-30T08:28:06.421473Z"},"id":"51-3rtTMj8K4","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'bark-voice-cloning-HuBERT-quantizer'...\n","remote: Enumerating objects: 1882, done.\u001b[K\n","remote: Counting objects: 100% (247/247), done.\u001b[K\n","remote: Compressing objects: 100% (123/123), done.\u001b[K\n","remote: Total 1882 (delta 141), reused 207 (delta 119), pack-reused 1635\u001b[K\n","Receiving objects: 100% (1882/1882), 319.75 MiB | 28.90 MiB/s, done.\n","Resolving deltas: 100% (142/142), done.\n","Looking in indexes: https://download.pytorch.org/whl/cu117\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!git clone https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer/\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-10-30T08:28:45.999948Z","iopub.status.busy":"2023-10-30T08:28:45.999548Z","iopub.status.idle":"2023-10-30T08:29:50.419243Z","shell.execute_reply":"2023-10-30T08:29:50.418261Z","shell.execute_reply.started":"2023-10-30T08:28:45.999914Z"},"id":"0TJDq-lPmYcV","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ignoring soundfile: markers 'platform_system == \"Windows\"' don't match your environment\n","Collecting audiolm-pytorch==1.1.4 (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading audiolm_pytorch-1.1.4-py3-none-any.whl (37 kB)\n","Collecting fairseq (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (0.16.4)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 4)) (0.1.99)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (4.33.0)\n","Requirement already satisfied: encodec in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 6)) (0.1.1)\n","Collecting sox (from -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 8))\n","  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (0.22.0)\n","Collecting beartype (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading beartype-0.16.4-py3-none-any.whl (819 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.1/819.1 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: einops>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (0.7.0)\n","Collecting ema-pytorch>=0.2.2 (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading ema_pytorch-0.2.4-py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.3.2)\n","Collecting lion-pytorch (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n","Collecting local-attention>=1.8.4 (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.2.2)\n","Requirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.0.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (4.66.1)\n","Collecting vector-quantize-pytorch>=1.5.14 (from audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1))\n","  Downloading vector_quantize_pytorch-1.10.4-py3-none-any.whl (20 kB)\n","Requirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (1.15.1)\n","Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (0.29.35)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.1 (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (2023.6.3)\n","Collecting sacrebleu>=1.4.12 (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bitarray (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading bitarray-2.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/286.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (1.23.5)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.12.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2023.9.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (4.6.3)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 5)) (0.3.3)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.0.9)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2))\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (0.9.0)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (4.9.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (5.9.3)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 2)) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 3)) (2023.7.22)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.11.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (3.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->audiolm-pytorch==1.1.4->-r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt (line 1)) (1.3.0)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10415054 sha256=f43093aa3d95644a49f05e0698f9b5814e9fc23f633b180d9d1a22da43c1935a\n","  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=2d92593bd08bc6d0b9d26da0999bb0ce865128d249cc1a24754d3911ac67866e\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n","Successfully built fairseq antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, sox, portalocker, omegaconf, beartype, sacrebleu, hydra-core, vector-quantize-pytorch, local-attention, lion-pytorch, ema-pytorch, fairseq, audiolm-pytorch\n","Successfully installed antlr4-python3-runtime-4.8 audiolm-pytorch-1.1.4 beartype-0.16.4 bitarray-2.8.2 ema-pytorch-0.2.4 fairseq-0.12.2 hydra-core-1.0.7 lion-pytorch-0.1.2 local-attention-1.9.0 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1 sox-1.4.1 vector-quantize-pytorch-1.10.4\n"]}],"source":["!pip install -r /kaggle/working/bark-voice-cloning-HuBERT-quantizer/requirements.txt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-30T08:29:50.421381Z","iopub.status.busy":"2023-10-30T08:29:50.421044Z","iopub.status.idle":"2023-10-30T08:29:50.428670Z","shell.execute_reply":"2023-10-30T08:29:50.427822Z","shell.execute_reply.started":"2023-10-30T08:29:50.421351Z"},"id":"KqnnUN5Nnq0y","outputId":"5bde104b-a23c-4ce6-f79b-1805a957fb29","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n","/kaggle/working/bark-voice-cloning-HuBERT-quantizer\n","/kaggle/working/bark-voice-cloning-HuBERT-quantizer\n"]}],"source":["import os\n","print(os.getcwd())\n","%cd '/kaggle/working/bark-voice-cloning-HuBERT-quantizer'\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141,"referenced_widgets":["deac3d6a9997427781e8efbdcafd9294","8e9970501d8c4915bfb1cc96175365f9","730f3fb888464a408bf703370cbb4aa5","b21922b9659a42ba9ba7e8c4e78580ba","37c5725eb9554b42b193af36468fe96d","2980b2e7677645778687564b33f8b817","5a6ecaff37c84fb7a988d63b86cb635d","4723356ccc414c7488e60d43b26c18f4","7539e02bd0724ca497e72df6b6e3caed","79f542c725664dd5bde481bdef479170","2f3544ff5b804087af84b1cff7cf9c2b"]},"execution":{"iopub.execute_input":"2023-10-30T08:30:28.655423Z","iopub.status.busy":"2023-10-30T08:30:28.654727Z","iopub.status.idle":"2023-10-30T08:30:32.970079Z","shell.execute_reply":"2023-10-30T08:30:32.969141Z","shell.execute_reply.started":"2023-10-30T08:30:28.655389Z"},"id":"_qp7F6wSifST","outputId":"2b87e7a3-9093-4372-805d-d416c97fa69c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading HuBERT base model\n","Downloaded HuBERT\n","Downloading HuBERT custom tokenizer\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1246a49bda4349b28fdd79f7a68f968a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)rt_base_ls960_14.pth:   0%|          | 0.00/104M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloaded tokenizer\n"]},{"data":{"text/plain":["'data/models/hubert/tokenizer.pth'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from bark_hubert_quantizer.hubert_manager import HuBERTManager\n","hubert_manager = HuBERTManager()\n","hubert_manager.make_sure_hubert_installed()\n","hubert_manager.make_sure_tokenizer_installed()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"execution":{"iopub.execute_input":"2023-10-30T08:30:32.972582Z","iopub.status.busy":"2023-10-30T08:30:32.972194Z","iopub.status.idle":"2023-10-30T08:31:11.205704Z","shell.execute_reply":"2023-10-30T08:31:11.204887Z","shell.execute_reply.started":"2023-10-30T08:30:32.972546Z"},"id":"zpy_FaspkDI-","outputId":"037c3cd7-e1de-44e7-b68a-28893e12a585","trusted":true},"outputs":[],"source":["from bark_hubert_quantizer.pre_kmeans_hubert import CustomHubert\n","from bark_hubert_quantizer.customtokenizer import CustomTokenizer\n","\n","# Load the HuBERT model\n","hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n","\n","# Load the CustomTokenizer model\n","tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth').to(device)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:38:04.211835Z","iopub.status.busy":"2023-10-30T08:38:04.211481Z","iopub.status.idle":"2023-10-30T08:38:04.339607Z","shell.execute_reply":"2023-10-30T08:38:04.338762Z","shell.execute_reply.started":"2023-10-30T08:38:04.211807Z"},"id":"H6BWVfPCkKKc","trusted":true},"outputs":[],"source":["audio_filepath = '/kaggle/working/output.wav' # the audio you want to clone (under 13 seconds)\n","wav, sr = torchaudio.load(audio_filepath)\n","wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n","wav = wav.to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:38:12.305408Z","iopub.status.busy":"2023-10-30T08:38:12.304510Z","iopub.status.idle":"2023-10-30T08:38:14.869948Z","shell.execute_reply":"2023-10-30T08:38:14.869064Z","shell.execute_reply.started":"2023-10-30T08:38:12.305375Z"},"id":"8hwd7Yq7kM0d","trusted":true},"outputs":[],"source":["semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n","semantic_tokens = tokenizer.get_token(semantic_vectors)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:38:17.866713Z","iopub.status.busy":"2023-10-30T08:38:17.865965Z","iopub.status.idle":"2023-10-30T08:38:17.934776Z","shell.execute_reply":"2023-10-30T08:38:17.934008Z","shell.execute_reply.started":"2023-10-30T08:38:17.866680Z"},"id":"dAUotKfakPQK","trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    encoded_frames = model.encode(wav.unsqueeze(0))\n","codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:38:20.217133Z","iopub.status.busy":"2023-10-30T08:38:20.216758Z","iopub.status.idle":"2023-10-30T08:38:20.222427Z","shell.execute_reply":"2023-10-30T08:38:20.221341Z","shell.execute_reply.started":"2023-10-30T08:38:20.217099Z"},"id":"tj-3Jo7KkRyo","trusted":true},"outputs":[],"source":["codes = codes.cpu().numpy()\n","# move semantic tokens to cpu\n","semantic_tokens = semantic_tokens.cpu().numpy()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:39:11.407085Z","iopub.status.busy":"2023-10-30T08:39:11.406133Z","iopub.status.idle":"2023-10-30T08:39:11.413042Z","shell.execute_reply":"2023-10-30T08:39:11.412080Z","shell.execute_reply.started":"2023-10-30T08:39:11.407054Z"},"id":"RUzBWkqUkT0J","trusted":true},"outputs":[],"source":["voice_name = 'voice_output' # whatever you want the name of the voice to be\n","output_path = '/kaggle/working/' + voice_name + '.npz'\n","np.savez(output_path, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:39:26.444733Z","iopub.status.busy":"2023-10-30T08:39:26.443484Z","iopub.status.idle":"2023-10-30T08:39:27.226371Z","shell.execute_reply":"2023-10-30T08:39:27.225556Z","shell.execute_reply.started":"2023-10-30T08:39:26.444696Z"},"id":"UHj8Zj5Xne0b","trusted":true},"outputs":[],"source":["import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","\n","from IPython.display import Audio\n","import nltk  # we'll use this to split into sentences\n","import numpy as np\n","\n","from bark.generation import (\n","    generate_text_semantic,\n","    preload_models,\n",")\n","from bark.api import semantic_to_waveform\n","from bark import generate_audio, SAMPLE_RATE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:39:32.659397Z","iopub.status.busy":"2023-10-30T08:39:32.658738Z","iopub.status.idle":"2023-10-30T08:40:45.915948Z","shell.execute_reply":"2023-10-30T08:40:45.915078Z","shell.execute_reply.started":"2023-10-30T08:39:32.659364Z"},"id":"RQgdUHlbp1w2","trusted":true},"outputs":[],"source":["preload_models()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:41:43.323663Z","iopub.status.busy":"2023-10-30T08:41:43.322877Z","iopub.status.idle":"2023-10-30T08:41:43.328808Z","shell.execute_reply":"2023-10-30T08:41:43.327856Z","shell.execute_reply.started":"2023-10-30T08:41:43.323631Z"},"trusted":true},"outputs":[],"source":["script = \"\"\"\n","Hey this is nandan trying to clone the voice in prompt.\n","This is to improve counsello project and to reduce the \n","human effort in creation of dataset. We need the dataset\n","of voices and thus we are using text to speech, this dataset\n","will be used to finetune whisper model which is voice to \n","text model.\n","\"\"\".replace(\"\\n\", \" \").strip()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:41:45.469432Z","iopub.status.busy":"2023-10-30T08:41:45.468393Z","iopub.status.idle":"2023-10-30T08:41:45.489884Z","shell.execute_reply":"2023-10-30T08:41:45.488883Z","shell.execute_reply.started":"2023-10-30T08:41:45.469384Z"},"trusted":true},"outputs":[],"source":["sentences = nltk.sent_tokenize(script)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:42:16.658870Z","iopub.status.busy":"2023-10-30T08:42:16.658504Z","iopub.status.idle":"2023-10-30T08:48:40.729236Z","shell.execute_reply":"2023-10-30T08:48:40.728376Z","shell.execute_reply.started":"2023-10-30T08:42:16.658844Z"},"id":"_gMbGCUvp2mm","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:19<00:00,  5.08it/s]\n","100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n","100%|██████████| 100/100 [00:36<00:00,  2.71it/s]\n","100%|██████████| 31/31 [00:24<00:00,  1.29it/s]\n","100%|██████████| 100/100 [00:10<00:00,  9.37it/s]\n","100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n","100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n","100%|██████████| 37/37 [00:29<00:00,  1.27it/s]\n","100%|██████████| 100/100 [00:25<00:00,  3.93it/s]\n","100%|██████████| 24/24 [00:18<00:00,  1.30it/s]\n","100%|██████████| 100/100 [00:18<00:00,  5.36it/s]\n","100%|██████████| 19/19 [00:14<00:00,  1.28it/s]\n","100%|██████████| 100/100 [00:10<00:00,  9.38it/s]\n","100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n","100%|██████████| 100/100 [00:46<00:00,  2.16it/s]\n","100%|██████████| 36/36 [00:28<00:00,  1.28it/s]\n"]}],"source":["GEN_TEMP = 0.6\n","SPEAKER = \"/kaggle/working/voice_output.npz\"\n","silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n","\n","pieces = []\n","for sentence in sentences:\n","    semantic_tokens = generate_text_semantic(\n","        sentence,\n","        history_prompt=SPEAKER,\n","        temp=GEN_TEMP,\n","        min_eos_p=0.05,  # this controls how likely the generation is to end\n","    )\n","\n","    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n","    pieces += [audio_array, silence.copy()]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-30T08:49:00.144851Z","iopub.status.busy":"2023-10-30T08:49:00.144258Z"},"id":"mVzfDzbMqFNB","trusted":true},"outputs":[],"source":["Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2980b2e7677645778687564b33f8b817":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f3544ff5b804087af84b1cff7cf9c2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37c5725eb9554b42b193af36468fe96d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4723356ccc414c7488e60d43b26c18f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a6ecaff37c84fb7a988d63b86cb635d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"730f3fb888464a408bf703370cbb4aa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4723356ccc414c7488e60d43b26c18f4","max":103981977,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7539e02bd0724ca497e72df6b6e3caed","value":103981977}},"7539e02bd0724ca497e72df6b6e3caed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79f542c725664dd5bde481bdef479170":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9970501d8c4915bfb1cc96175365f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2980b2e7677645778687564b33f8b817","placeholder":"​","style":"IPY_MODEL_5a6ecaff37c84fb7a988d63b86cb635d","value":"Downloading (…)rt_base_ls960_14.pth: 100%"}},"b21922b9659a42ba9ba7e8c4e78580ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79f542c725664dd5bde481bdef479170","placeholder":"​","style":"IPY_MODEL_2f3544ff5b804087af84b1cff7cf9c2b","value":" 104M/104M [00:03&lt;00:00, 28.4MB/s]"}},"deac3d6a9997427781e8efbdcafd9294":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e9970501d8c4915bfb1cc96175365f9","IPY_MODEL_730f3fb888464a408bf703370cbb4aa5","IPY_MODEL_b21922b9659a42ba9ba7e8c4e78580ba"],"layout":"IPY_MODEL_37c5725eb9554b42b193af36468fe96d"}}}}},"nbformat":4,"nbformat_minor":4}
